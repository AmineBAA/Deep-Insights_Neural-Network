{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmineBAA/Deep-Insights_Neural-Network/blob/main/Resnet_TorchVision_Interpret.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IigRlmI8siv7"
      },
      "source": [
        "# Model Interpretation for Pretrained ResNet Model: Neural activation classification with Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiTZe7yasiwA"
      },
      "source": [
        "This notebook demonstrates how to apply model interpretability algorithms on pretrained ResNet model using a handpicked image and visualizes the attributions for each pixel by overlaying them on the image.\n",
        "\n",
        "Captum library privides function of Layer Conductance, that helps to evaluate importance of each neuron within a given Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install captum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0EeH6IIs9MF",
        "outputId": "61b235dd-0596-4f3f-af9e-01c155ec9299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting captum\n",
            "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->captum) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->captum) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8J2PydasiwB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "\n",
        "from captum.attr import IntegratedGradients\n",
        "from captum.attr import GradientShap\n",
        "from captum.attr import Occlusion\n",
        "from captum.attr import NoiseTunnel\n",
        "from captum.attr import visualization as viz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "UHUEdtza_D7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(models)"
      ],
      "metadata": {
        "id": "e4dEuJpH-SX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8EpTB_ysiwD"
      },
      "source": [
        "## 1- Loading the model and the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s97qQ39fsiwE"
      },
      "source": [
        "Loads pretrained Resnet model and sets it to eval mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CavnkdmesiwE",
        "outputId": "865f9aad-9aa4-4d3b-cfd4-154ceb2968cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 273MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afQl4211siwF"
      },
      "source": [
        "Downloads the list of classes/labels for ImageNet dataset and reads them into the memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0brGoEQsiwF",
        "outputId": "b3508237-893b-4168-c3d8-52974c2fbafa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-10 11:40:34--  https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.153.46, 52.217.90.190, 52.216.142.46, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.153.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35363 (35K) [application/octet-stream]\n",
            "Saving to: ‘/root/.torch/models/imagenet_class_index.json’\n",
            "\n",
            "\r          imagenet_   0%[                    ]       0  --.-KB/s               \rimagenet_class_inde 100%[===================>]  34.53K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-09-10 11:40:35 (14.5 MB/s) - ‘/root/.torch/models/imagenet_class_index.json’ saved [35363/35363]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -P $HOME/.torch/models https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX5Nbt_9siwH"
      },
      "outputs": [],
      "source": [
        "labels_path = os.getenv(\"HOME\") + '/.torch/models/imagenet_class_index.json'\n",
        "with open(labels_path) as json_data:\n",
        "    idx_to_labels = json.load(json_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1frMEODsiwH"
      },
      "source": [
        "Defines transformers and normalizing functions for the image.\n",
        "It also loads an image from the `img/resnet/` folder that will be used for interpretation purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOcXPDP4siwI"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        " transforms.Resize(256),\n",
        " transforms.CenterCrop(224),\n",
        " transforms.ToTensor()\n",
        "])\n",
        "\n",
        "transform_normalize = transforms.Normalize(\n",
        "     mean=[0.485, 0.456, 0.406],\n",
        "     std=[0.229, 0.224, 0.225]\n",
        " )\n",
        "\n",
        "img = Image.open('/content/concept/concept_1.jpg')\n",
        "\n",
        "transformed_img = transform(img)\n",
        "\n",
        "input = transform_normalize(transformed_img)\n",
        "input = input.unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNZJG6CAsiwI"
      },
      "source": [
        "Predict the class of the input image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-ZSeZBGsiwI",
        "outputId": "942de871-a37d-46dc-af57-5de6cc438f6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: lion ( 0.9131245017051697 )\n"
          ]
        }
      ],
      "source": [
        "output = model(input)\n",
        "output = F.softmax(output, dim=1)\n",
        "prediction_score, pred_label_idx = torch.topk(output, 1)\n",
        "\n",
        "pred_label_idx.squeeze_()\n",
        "predicted_label = idx_to_labels[str(pred_label_idx.item())][1]\n",
        "print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label_idx.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fYC_z4-psCS",
        "outputId": "f24ef729-b4c7-4e60-f306-49d8611c4dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "291"
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4cfOWXUsiwI"
      },
      "source": [
        "## 2- Gradient-based attribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vrUrMHNsiwI"
      },
      "source": [
        "Let's compute attributions using Integrated Gradients and visualize them on the image. Integrated gradients computes the integral of the gradients of the output of the model for the predicted class `pred_label_idx` with respect to the input image pixels along the path from the black image to our input image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze2ef-imsiwI",
        "outputId": "a931b3d1-142f-47ea-c78d-7b906efddac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: goldfinch ( 0.9933870434761047 )\n"
          ]
        }
      ],
      "source": [
        "print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')\n",
        "\n",
        "integrated_gradients = IntegratedGradients(model)\n",
        "attributions_ig = integrated_gradients.attribute(input, target=pred_label_idx, n_steps=200)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuHqBhVNsiwJ"
      },
      "source": [
        "Let's visualize the image and corresponding attributions by overlaying the latter on the image."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.features.denseblock1"
      ],
      "metadata": {
        "id": "gHmrjh1BFlIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_conv=model.layer4"
      ],
      "metadata": {
        "id": "6hT9CiTgdBm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_conv"
      ],
      "metadata": {
        "id": "E-DCL1jxdzEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert convolutional layer to fully connected"
      ],
      "metadata": {
        "id": "Vq01NjdTdbUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(model)"
      ],
      "metadata": {
        "id": "Oieorji6fpUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- Layer Conductance"
      ],
      "metadata": {
        "id": "upGS-IL4dg75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from captum.attr import LayerConductance\n",
        "cond =LayerConductance(model, layer_conv)"
      ],
      "metadata": {
        "id": "tA1azY7WtvwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond_vals = cond.attribute(input,target=291)  #11 class of 'goldfinch' in imagenet dataset\n",
        "cond_vals = cond_vals.detach().numpy()"
      ],
      "metadata": {
        "id": "_AoVgOMouoaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond_vals.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iygzToetrbDe",
        "outputId": "a5a05807-5fe1-460a-92e2-727f4c3dcbb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 512, 7, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 468
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cond_vals_flatten=cond_vals.reshape((512,7*7))"
      ],
      "metadata": {
        "id": "s0jusIxAu9pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond_vals_flatten.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-ZZhRJur9cc",
        "outputId": "86a8a83d-2014-4b0c-ef2c-b967af52a457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 445
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(cond_vals[50][0], 100);\n",
        "plt.title(\"Neuron 50 Distribution\")\n",
        "plt.figure()\n",
        "plt.hist(cond_vals[19][0], 100);\n",
        "plt.title(\"Neuron 19 Distribution\");"
      ],
      "metadata": {
        "id": "3kB-Q6j7u9lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper method to print importances and visualize distribution\n",
        "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\"):\n",
        "    print(title)\n",
        "    for i in range(len(feature_names)):\n",
        "        print(feature_names[i], \": \", '%.4f'%(importances[i]))\n",
        "    x_pos = (np.arange(len(feature_names)))\n",
        "    if plot:\n",
        "        plt.figure(figsize=(12,6))\n",
        "        cmap = plt.get_cmap('copper')\n",
        "        norm = plt.Normalize(importances.min(), importances.max())\n",
        "        colors = cmap(norm(importances))\n",
        "        plt.bar(x_pos, importances, align='center',color=colors)\n",
        "        plt.xticks(x_pos, feature_names, wrap=True)\n",
        "        plt.xlabel(axis_title)\n",
        "        plt.title(title)\n"
      ],
      "metadata": {
        "id": "hbK_69jsu9gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_importances(range(512),np.mean(cond_vals_flatten, axis=1),title=\"Average Neuron Importances\", axis_title=\"Neurons\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vWENOWSwqYsI",
        "outputId": "34ebb1db-824e-4d8d-de06-7220fcdc9bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Neuron Importances\n",
            "0 :  -0.0007\n",
            "1 :  0.0010\n",
            "2 :  0.0022\n",
            "3 :  0.0000\n",
            "4 :  -0.0007\n",
            "5 :  0.0062\n",
            "6 :  0.0066\n",
            "7 :  -0.0008\n",
            "8 :  0.0002\n",
            "9 :  0.0084\n",
            "10 :  -0.0004\n",
            "11 :  0.0006\n",
            "12 :  -0.0001\n",
            "13 :  0.0007\n",
            "14 :  0.0002\n",
            "15 :  -0.0001\n",
            "16 :  -0.0000\n",
            "17 :  -0.0004\n",
            "18 :  -0.0004\n",
            "19 :  0.0012\n",
            "20 :  0.0010\n",
            "21 :  0.0079\n",
            "22 :  -0.0004\n",
            "23 :  -0.0001\n",
            "24 :  -0.0004\n",
            "25 :  -0.0001\n",
            "26 :  -0.0001\n",
            "27 :  -0.0006\n",
            "28 :  0.0065\n",
            "29 :  -0.0014\n",
            "30 :  -0.0001\n",
            "31 :  0.0005\n",
            "32 :  0.0018\n",
            "33 :  0.0004\n",
            "34 :  -0.0001\n",
            "35 :  -0.0006\n",
            "36 :  -0.0001\n",
            "37 :  -0.0002\n",
            "38 :  0.0005\n",
            "39 :  -0.0001\n",
            "40 :  0.0000\n",
            "41 :  -0.0000\n",
            "42 :  -0.0014\n",
            "43 :  0.0075\n",
            "44 :  -0.0006\n",
            "45 :  -0.0004\n",
            "46 :  0.0006\n",
            "47 :  -0.0001\n",
            "48 :  -0.0003\n",
            "49 :  -0.0018\n",
            "50 :  0.0001\n",
            "51 :  0.0067\n",
            "52 :  -0.0001\n",
            "53 :  -0.0001\n",
            "54 :  0.0005\n",
            "55 :  -0.0001\n",
            "56 :  -0.0009\n",
            "57 :  0.0005\n",
            "58 :  0.0006\n",
            "59 :  0.0001\n",
            "60 :  0.0017\n",
            "61 :  0.0090\n",
            "62 :  -0.0024\n",
            "63 :  0.0004\n",
            "64 :  0.0006\n",
            "65 :  0.0023\n",
            "66 :  -0.0010\n",
            "67 :  -0.0001\n",
            "68 :  -0.0003\n",
            "69 :  -0.0000\n",
            "70 :  -0.0006\n",
            "71 :  -0.0002\n",
            "72 :  0.0000\n",
            "73 :  -0.0003\n",
            "74 :  -0.0020\n",
            "75 :  0.0000\n",
            "76 :  -0.0004\n",
            "77 :  0.0095\n",
            "78 :  0.0001\n",
            "79 :  -0.0004\n",
            "80 :  0.0020\n",
            "81 :  0.0013\n",
            "82 :  -0.0001\n",
            "83 :  -0.0007\n",
            "84 :  -0.0003\n",
            "85 :  0.0023\n",
            "86 :  -0.0001\n",
            "87 :  0.0005\n",
            "88 :  -0.0012\n",
            "89 :  -0.0001\n",
            "90 :  -0.0005\n",
            "91 :  0.0016\n",
            "92 :  0.0001\n",
            "93 :  -0.0005\n",
            "94 :  0.0000\n",
            "95 :  -0.0003\n",
            "96 :  0.0000\n",
            "97 :  0.0065\n",
            "98 :  -0.0000\n",
            "99 :  -0.0004\n",
            "100 :  0.0003\n",
            "101 :  0.0006\n",
            "102 :  -0.0008\n",
            "103 :  -0.0000\n",
            "104 :  0.0037\n",
            "105 :  0.0008\n",
            "106 :  -0.0009\n",
            "107 :  -0.0001\n",
            "108 :  -0.0003\n",
            "109 :  -0.0003\n",
            "110 :  0.0000\n",
            "111 :  -0.0011\n",
            "112 :  -0.0002\n",
            "113 :  -0.0000\n",
            "114 :  -0.0004\n",
            "115 :  0.0010\n",
            "116 :  0.0003\n",
            "117 :  -0.0024\n",
            "118 :  0.0000\n",
            "119 :  -0.0001\n",
            "120 :  -0.0008\n",
            "121 :  -0.0001\n",
            "122 :  0.0015\n",
            "123 :  -0.0001\n",
            "124 :  -0.0003\n",
            "125 :  -0.0002\n",
            "126 :  0.0005\n",
            "127 :  0.0017\n",
            "128 :  0.0004\n",
            "129 :  0.0032\n",
            "130 :  -0.0005\n",
            "131 :  0.0001\n",
            "132 :  -0.0005\n",
            "133 :  -0.0002\n",
            "134 :  0.0001\n",
            "135 :  0.0000\n",
            "136 :  0.0026\n",
            "137 :  -0.0006\n",
            "138 :  0.0015\n",
            "139 :  -0.0002\n",
            "140 :  0.0024\n",
            "141 :  0.0013\n",
            "142 :  -0.0028\n",
            "143 :  -0.0000\n",
            "144 :  0.0035\n",
            "145 :  -0.0005\n",
            "146 :  0.0000\n",
            "147 :  0.0004\n",
            "148 :  -0.0007\n",
            "149 :  -0.0000\n",
            "150 :  -0.0001\n",
            "151 :  -0.0017\n",
            "152 :  -0.0003\n",
            "153 :  -0.0003\n",
            "154 :  0.0001\n",
            "155 :  -0.0005\n",
            "156 :  0.0217\n",
            "157 :  -0.0005\n",
            "158 :  0.0045\n",
            "159 :  -0.0002\n",
            "160 :  0.0029\n",
            "161 :  0.0013\n",
            "162 :  -0.0002\n",
            "163 :  -0.0020\n",
            "164 :  -0.0000\n",
            "165 :  -0.0003\n",
            "166 :  -0.0000\n",
            "167 :  0.0003\n",
            "168 :  -0.0006\n",
            "169 :  -0.0001\n",
            "170 :  0.0000\n",
            "171 :  -0.0003\n",
            "172 :  -0.0004\n",
            "173 :  0.0022\n",
            "174 :  -0.0004\n",
            "175 :  -0.0001\n",
            "176 :  0.0000\n",
            "177 :  -0.0000\n",
            "178 :  0.0017\n",
            "179 :  0.0040\n",
            "180 :  0.0074\n",
            "181 :  0.0016\n",
            "182 :  -0.0002\n",
            "183 :  -0.0010\n",
            "184 :  -0.0000\n",
            "185 :  0.0010\n",
            "186 :  0.0016\n",
            "187 :  -0.0010\n",
            "188 :  -0.0005\n",
            "189 :  0.0035\n",
            "190 :  -0.0001\n",
            "191 :  -0.0000\n",
            "192 :  0.0002\n",
            "193 :  -0.0020\n",
            "194 :  0.0004\n",
            "195 :  -0.0007\n",
            "196 :  -0.0006\n",
            "197 :  -0.0011\n",
            "198 :  -0.0011\n",
            "199 :  -0.0008\n",
            "200 :  -0.0003\n",
            "201 :  0.0000\n",
            "202 :  0.0159\n",
            "203 :  -0.0001\n",
            "204 :  -0.0008\n",
            "205 :  -0.0000\n",
            "206 :  -0.0001\n",
            "207 :  -0.0002\n",
            "208 :  0.0016\n",
            "209 :  -0.0010\n",
            "210 :  -0.0007\n",
            "211 :  -0.0005\n",
            "212 :  0.0001\n",
            "213 :  0.0002\n",
            "214 :  -0.0008\n",
            "215 :  -0.0013\n",
            "216 :  -0.0001\n",
            "217 :  -0.0004\n",
            "218 :  -0.0007\n",
            "219 :  0.0038\n",
            "220 :  -0.0001\n",
            "221 :  -0.0022\n",
            "222 :  -0.0001\n",
            "223 :  -0.0007\n",
            "224 :  0.0002\n",
            "225 :  -0.0002\n",
            "226 :  -0.0005\n",
            "227 :  -0.0001\n",
            "228 :  -0.0001\n",
            "229 :  -0.0006\n",
            "230 :  0.0055\n",
            "231 :  -0.0002\n",
            "232 :  0.0000\n",
            "233 :  -0.0003\n",
            "234 :  -0.0002\n",
            "235 :  -0.0001\n",
            "236 :  0.0005\n",
            "237 :  -0.0001\n",
            "238 :  -0.0001\n",
            "239 :  0.0009\n",
            "240 :  0.0001\n",
            "241 :  0.0000\n",
            "242 :  0.0187\n",
            "243 :  -0.0000\n",
            "244 :  0.0003\n",
            "245 :  -0.0003\n",
            "246 :  -0.0001\n",
            "247 :  -0.0001\n",
            "248 :  -0.0000\n",
            "249 :  0.0003\n",
            "250 :  0.0066\n",
            "251 :  -0.0000\n",
            "252 :  -0.0007\n",
            "253 :  -0.0015\n",
            "254 :  0.0003\n",
            "255 :  0.0109\n",
            "256 :  -0.0000\n",
            "257 :  -0.0015\n",
            "258 :  0.0014\n",
            "259 :  -0.0002\n",
            "260 :  0.0003\n",
            "261 :  0.0011\n",
            "262 :  0.0002\n",
            "263 :  0.0060\n",
            "264 :  0.0022\n",
            "265 :  0.0007\n",
            "266 :  -0.0004\n",
            "267 :  -0.0003\n",
            "268 :  0.0001\n",
            "269 :  -0.0007\n",
            "270 :  -0.0000\n",
            "271 :  0.0050\n",
            "272 :  -0.0010\n",
            "273 :  -0.0006\n",
            "274 :  -0.0000\n",
            "275 :  -0.0001\n",
            "276 :  0.0004\n",
            "277 :  0.0000\n",
            "278 :  0.0025\n",
            "279 :  -0.0000\n",
            "280 :  -0.0000\n",
            "281 :  0.0000\n",
            "282 :  0.0007\n",
            "283 :  -0.0001\n",
            "284 :  0.0001\n",
            "285 :  0.0017\n",
            "286 :  -0.0000\n",
            "287 :  0.0000\n",
            "288 :  0.0025\n",
            "289 :  -0.0000\n",
            "290 :  -0.0001\n",
            "291 :  0.0000\n",
            "292 :  0.0077\n",
            "293 :  0.0002\n",
            "294 :  0.0001\n",
            "295 :  0.0000\n",
            "296 :  -0.0002\n",
            "297 :  0.0023\n",
            "298 :  -0.0009\n",
            "299 :  -0.0009\n",
            "300 :  0.0026\n",
            "301 :  0.0090\n",
            "302 :  0.0001\n",
            "303 :  -0.0004\n",
            "304 :  0.0000\n",
            "305 :  0.0002\n",
            "306 :  0.0036\n",
            "307 :  0.0007\n",
            "308 :  -0.0002\n",
            "309 :  0.0035\n",
            "310 :  0.0024\n",
            "311 :  -0.0003\n",
            "312 :  -0.0002\n",
            "313 :  0.0013\n",
            "314 :  -0.0014\n",
            "315 :  0.0077\n",
            "316 :  0.0002\n",
            "317 :  -0.0018\n",
            "318 :  -0.0001\n",
            "319 :  -0.0002\n",
            "320 :  -0.0002\n",
            "321 :  -0.0005\n",
            "322 :  -0.0001\n",
            "323 :  -0.0002\n",
            "324 :  -0.0007\n",
            "325 :  -0.0005\n",
            "326 :  -0.0001\n",
            "327 :  0.0004\n",
            "328 :  0.0008\n",
            "329 :  -0.0001\n",
            "330 :  -0.0001\n",
            "331 :  0.0013\n",
            "332 :  -0.0000\n",
            "333 :  0.0000\n",
            "334 :  0.0013\n",
            "335 :  -0.0003\n",
            "336 :  0.0049\n",
            "337 :  -0.0013\n",
            "338 :  -0.0004\n",
            "339 :  0.0001\n",
            "340 :  -0.0001\n",
            "341 :  -0.0003\n",
            "342 :  0.0002\n",
            "343 :  0.0018\n",
            "344 :  0.0035\n",
            "345 :  0.0032\n",
            "346 :  0.0099\n",
            "347 :  -0.0006\n",
            "348 :  -0.0005\n",
            "349 :  0.0004\n",
            "350 :  0.0000\n",
            "351 :  -0.0001\n",
            "352 :  -0.0002\n",
            "353 :  0.0001\n",
            "354 :  0.0001\n",
            "355 :  0.0000\n",
            "356 :  0.0047\n",
            "357 :  -0.0003\n",
            "358 :  0.0002\n",
            "359 :  0.0015\n",
            "360 :  -0.0001\n",
            "361 :  0.0004\n",
            "362 :  0.0001\n",
            "363 :  0.0032\n",
            "364 :  0.0005\n",
            "365 :  -0.0005\n",
            "366 :  0.0000\n",
            "367 :  -0.0009\n",
            "368 :  0.0005\n",
            "369 :  0.0122\n",
            "370 :  -0.0006\n",
            "371 :  0.0004\n",
            "372 :  0.0015\n",
            "373 :  -0.0008\n",
            "374 :  0.0011\n",
            "375 :  -0.0002\n",
            "376 :  -0.0010\n",
            "377 :  -0.0000\n",
            "378 :  0.0025\n",
            "379 :  -0.0005\n",
            "380 :  0.0001\n",
            "381 :  0.0010\n",
            "382 :  0.0001\n",
            "383 :  -0.0000\n",
            "384 :  -0.0000\n",
            "385 :  0.0051\n",
            "386 :  -0.0003\n",
            "387 :  -0.0002\n",
            "388 :  0.0001\n",
            "389 :  -0.0001\n",
            "390 :  -0.0001\n",
            "391 :  -0.0002\n",
            "392 :  -0.0002\n",
            "393 :  0.0009\n",
            "394 :  -0.0006\n",
            "395 :  -0.0005\n",
            "396 :  -0.0004\n",
            "397 :  0.0000\n",
            "398 :  -0.0004\n",
            "399 :  -0.0004\n",
            "400 :  0.0009\n",
            "401 :  0.0001\n",
            "402 :  0.0008\n",
            "403 :  -0.0003\n",
            "404 :  0.0013\n",
            "405 :  0.0006\n",
            "406 :  0.0010\n",
            "407 :  -0.0001\n",
            "408 :  0.0005\n",
            "409 :  0.0011\n",
            "410 :  0.0105\n",
            "411 :  0.0001\n",
            "412 :  0.0007\n",
            "413 :  -0.0002\n",
            "414 :  0.0038\n",
            "415 :  -0.0001\n",
            "416 :  -0.0001\n",
            "417 :  0.0002\n",
            "418 :  0.0007\n",
            "419 :  0.0002\n",
            "420 :  0.0001\n",
            "421 :  -0.0001\n",
            "422 :  0.0005\n",
            "423 :  0.0006\n",
            "424 :  0.0052\n",
            "425 :  -0.0001\n",
            "426 :  -0.0001\n",
            "427 :  0.0056\n",
            "428 :  -0.0001\n",
            "429 :  0.0000\n",
            "430 :  -0.0002\n",
            "431 :  -0.0001\n",
            "432 :  0.0002\n",
            "433 :  0.0089\n",
            "434 :  -0.0008\n",
            "435 :  0.0000\n",
            "436 :  -0.0002\n",
            "437 :  -0.0005\n",
            "438 :  -0.0003\n",
            "439 :  0.0043\n",
            "440 :  -0.0002\n",
            "441 :  -0.0008\n",
            "442 :  0.0011\n",
            "443 :  0.0031\n",
            "444 :  0.0017\n",
            "445 :  0.0004\n",
            "446 :  -0.0003\n",
            "447 :  -0.0003\n",
            "448 :  0.0002\n",
            "449 :  -0.0001\n",
            "450 :  -0.0009\n",
            "451 :  -0.0011\n",
            "452 :  -0.0000\n",
            "453 :  -0.0007\n",
            "454 :  -0.0010\n",
            "455 :  -0.0001\n",
            "456 :  0.0003\n",
            "457 :  0.0002\n",
            "458 :  -0.0007\n",
            "459 :  -0.0004\n",
            "460 :  -0.0000\n",
            "461 :  0.0054\n",
            "462 :  -0.0008\n",
            "463 :  0.0051\n",
            "464 :  -0.0002\n",
            "465 :  -0.0021\n",
            "466 :  -0.0001\n",
            "467 :  0.0017\n",
            "468 :  0.0001\n",
            "469 :  -0.0000\n",
            "470 :  -0.0004\n",
            "471 :  -0.0005\n",
            "472 :  0.0002\n",
            "473 :  -0.0011\n",
            "474 :  0.0010\n",
            "475 :  -0.0004\n",
            "476 :  -0.0003\n",
            "477 :  -0.0002\n",
            "478 :  0.0004\n",
            "479 :  -0.0003\n",
            "480 :  -0.0004\n",
            "481 :  0.0009\n",
            "482 :  -0.0001\n",
            "483 :  -0.0001\n",
            "484 :  0.0005\n",
            "485 :  -0.0002\n",
            "486 :  -0.0005\n",
            "487 :  -0.0003\n",
            "488 :  -0.0003\n",
            "489 :  0.0002\n",
            "490 :  0.0003\n",
            "491 :  0.0014\n",
            "492 :  0.0107\n",
            "493 :  0.0142\n",
            "494 :  0.0007\n",
            "495 :  0.0004\n",
            "496 :  -0.0003\n",
            "497 :  -0.0004\n",
            "498 :  0.0000\n",
            "499 :  0.0001\n",
            "500 :  -0.0008\n",
            "501 :  -0.0005\n",
            "502 :  -0.0005\n",
            "503 :  -0.0007\n",
            "504 :  -0.0003\n",
            "505 :  0.0065\n",
            "506 :  0.0001\n",
            "507 :  0.0000\n",
            "508 :  -0.0001\n",
            "509 :  0.0000\n",
            "510 :  -0.0001\n",
            "511 :  0.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(cond_vals_flatten[17,])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RklF-xzErBaP",
        "outputId": "58572434-1587-46df-8620-d6cdf6a44aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.00033750583"
            ]
          },
          "metadata": {},
          "execution_count": 471
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importance=np.mean(cond_vals_flatten, axis=1)\n",
        "np.where(importance==np.max(importance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K82LxQiyqfHH",
        "outputId": "efd5b9bf-11ea-4831-fc3e-a0d5588376e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([156]),)"
            ]
          },
          "metadata": {},
          "execution_count": 489
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rang=np.where(importance==np.max(importance))\n",
        "rang=np.mean(rang)"
      ],
      "metadata": {
        "id": "pWMzMmgo7huE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rang=[76]"
      ],
      "metadata": {
        "id": "eMRhC6RR8hdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector=[]\n",
        "\n",
        "for i in range(512):\n",
        "  vector.append(np.mean(cond_vals_flatten[i,]))"
      ],
      "metadata": {
        "id": "AiqNoGheqw7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################"
      ],
      "metadata": {
        "id": "g-ZIdBJru9d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Rename files\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Replace these values with your desired folder and renaming criteria\n",
        "folder_path = '/content/concept'\n",
        "file_extension = '.jpg'  # Change to the desired file extension\n",
        "name_pattern = 'concept_{}'  # Change to your preferred name pattern\n",
        "\n",
        "# Get a list of files that match the criteria\n",
        "files_to_rename = glob.glob(os.path.join(folder_path, f\"*{file_extension}\"))\n",
        "\n",
        "# Iterate through the files and rename them\n",
        "for index, old_file_path in enumerate(files_to_rename):\n",
        "    # Extract the file's base name without extension\n",
        "    base_name = os.path.splitext(os.path.basename(old_file_path))[0]\n",
        "\n",
        "    # Construct the new name using the pattern\n",
        "    new_name = name_pattern.format(index + 1)\n",
        "\n",
        "    # Create the new file path with the same extension as the old file\n",
        "    new_file_path = os.path.join(folder_path, f\"{new_name}{file_extension}\")\n",
        "\n",
        "    # Rename the file\n",
        "    os.rename(old_file_path, new_file_path)\n",
        "\n",
        "print(\"Files renamed successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K2J5EGP-Cby",
        "outputId": "776beb68-6127-4218-b243-a7cf8bafd699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files renamed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_array=vector\n",
        "y=[prediction_score.squeeze().item()]\n",
        "label=['lion']\n",
        "for i in range(2,28):\n",
        "  transform = transforms.Compose([ transforms.Resize(256),transforms.CenterCrop(224),transforms.ToTensor()])\n",
        "  transform_normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "  img = Image.open('/content/concept/concept_'+str(i)+'.jpg')\n",
        "  transformed_img = transform(img)\n",
        "  input = transform_normalize(transformed_img)\n",
        "  input = input.unsqueeze(0)\n",
        "  output = model(input)\n",
        "  output = F.softmax(output, dim=1)\n",
        "  prediction_score, pred_label_idx = torch.topk(output, 1)\n",
        "  pred_label_idx.squeeze_()\n",
        "  predicted_label = idx_to_labels[str(pred_label_idx.item())][1]\n",
        "  y.append(prediction_score.squeeze().item())\n",
        "  label.append(predicted_label)\n",
        "  index=pred_label_idx.item()\n",
        "  cond_vals = cond.attribute(input,target=index)\n",
        "  cond_vals = cond_vals.detach().numpy()\n",
        "  cond_vals_flatten=cond_vals.reshape((512,7*7))\n",
        "  var=[]\n",
        "  for j in range(512):\n",
        "    var.append(np.mean(cond_vals_flatten[j,]))\n",
        "\n",
        "\n",
        "  merged_array = np.column_stack((merged_array,var))\n",
        "  rang.append(np.mean(np.where(np.mean(cond_vals_flatten, axis=1)==np.max(np.mean(cond_vals_flatten, axis=1)))))"
      ],
      "metadata": {
        "id": "mk30eHGzwFoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_array.shape"
      ],
      "metadata": {
        "id": "ul45TEVvwIZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdM1F-Hx8NrE",
        "outputId": "6f190107-cb35-4a04-8449-647c3acbb3b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 475
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################################"
      ],
      "metadata": {
        "id": "_4PEjkS6wFj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Detect outlier neuron\n",
        "def detect_outliers_zscore(data, threshold=4):\n",
        "    z_scores = (data - data.mean()) / data.std()\n",
        "    return np.where(np.abs(z_scores) > threshold)\n",
        "\n",
        "outlier_indices = detect_outliers_zscore(importance)\n",
        "print(\"Outlier indices:\", outlier_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2BnpRSs3B41",
        "outputId": "cb2bb0ae-06bd-482b-dadc-505cde411280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outlier indices: (array([156, 202, 242, 369, 493]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_indices[1].shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4SPvt3C4Gh3",
        "outputId": "f6d50eca-83de-4f07-806c-e79a87a9c7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "All_data=merged_array"
      ],
      "metadata": {
        "id": "zJF5ILhIFs6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################"
      ],
      "metadata": {
        "id": "HmOMdM8o4wL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "All_data=np.concatenate((All_data,merged_array))"
      ],
      "metadata": {
        "id": "MVr36BmwJtq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "All_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8VzB2vDFvZI",
        "outputId": "552dd815-0da7-4b3f-b5f4-d0bb89fcdb0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4480, 299)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=pd.DataFrame(np.transpose(All_data))"
      ],
      "metadata": {
        "id": "M64xsQ4LU9tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4- Data processing"
      ],
      "metadata": {
        "id": "zModE7Ua9c1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "5fq09AxE9BFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=pd.DataFrame(np.transpose(merged_array))"
      ],
      "metadata": {
        "id": "cRJGDP2y84D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_bis=pd.DataFrame(np.transpose(merged_array))"
      ],
      "metadata": {
        "id": "PATVgIuwOPB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "I3tW1XjM83ii",
        "outputId": "269be214-2ccc-49d6-d83a-4e5e498ab1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0  0.000075 -0.000472  0.000911 -0.000558 -0.000210  0.000728  0.000435   \n",
              "1 -0.000094 -0.000918  0.000047 -0.000788  0.000836  0.003866 -0.000262   \n",
              "2 -0.000301 -0.004723 -0.000028 -0.000488 -0.000082  0.000015 -0.000032   \n",
              "3 -0.000467 -0.000024  0.000575 -0.000436 -0.000581  0.001565  0.000517   \n",
              "4 -0.000211  0.000602  0.000401  0.000050  0.000215 -0.000028 -0.000181   \n",
              "\n",
              "        7         8         9    ...       246       247       248       249  \\\n",
              "0  0.000249 -0.003544 -0.000089  ...  0.000230 -0.000120  0.000022 -0.000243   \n",
              "1  0.000394  0.000972  0.001301  ... -0.002074  0.000675  0.000642  0.002054   \n",
              "2 -0.000196 -0.001213 -0.000569  ... -0.000630  0.000387  0.000474 -0.001055   \n",
              "3  0.000475 -0.003071 -0.000840  ...  0.000679 -0.000076  0.000345  0.000296   \n",
              "4  0.000731  0.000742  0.000297  ... -0.000326  0.000312  0.000491  0.000495   \n",
              "\n",
              "        250       251       252       253       254       255  \n",
              "0  0.000022  0.000352  0.003680  0.000468 -0.000218  0.002066  \n",
              "1  0.000390 -0.000314  0.004354  0.000843 -0.001050  0.001511  \n",
              "2  0.000648 -0.001065  0.003007  0.000007 -0.000189  0.001184  \n",
              "3 -0.000462  0.000490  0.003847 -0.000157  0.000026  0.001716  \n",
              "4  0.000673 -0.001379  0.003167 -0.000271  0.000603 -0.000206  \n",
              "\n",
              "[5 rows x 256 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b2137b3-3b7e-4123-bd16-2bd4aed8cf53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000075</td>\n",
              "      <td>-0.000472</td>\n",
              "      <td>0.000911</td>\n",
              "      <td>-0.000558</td>\n",
              "      <td>-0.000210</td>\n",
              "      <td>0.000728</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>-0.003544</td>\n",
              "      <td>-0.000089</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000230</td>\n",
              "      <td>-0.000120</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>-0.000243</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000352</td>\n",
              "      <td>0.003680</td>\n",
              "      <td>0.000468</td>\n",
              "      <td>-0.000218</td>\n",
              "      <td>0.002066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.000094</td>\n",
              "      <td>-0.000918</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>-0.000788</td>\n",
              "      <td>0.000836</td>\n",
              "      <td>0.003866</td>\n",
              "      <td>-0.000262</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>0.000972</td>\n",
              "      <td>0.001301</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002074</td>\n",
              "      <td>0.000675</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.002054</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>-0.000314</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>0.000843</td>\n",
              "      <td>-0.001050</td>\n",
              "      <td>0.001511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.000301</td>\n",
              "      <td>-0.004723</td>\n",
              "      <td>-0.000028</td>\n",
              "      <td>-0.000488</td>\n",
              "      <td>-0.000082</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>-0.000032</td>\n",
              "      <td>-0.000196</td>\n",
              "      <td>-0.001213</td>\n",
              "      <td>-0.000569</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000630</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>-0.001055</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>-0.001065</td>\n",
              "      <td>0.003007</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-0.000189</td>\n",
              "      <td>0.001184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.000467</td>\n",
              "      <td>-0.000024</td>\n",
              "      <td>0.000575</td>\n",
              "      <td>-0.000436</td>\n",
              "      <td>-0.000581</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.000517</td>\n",
              "      <td>0.000475</td>\n",
              "      <td>-0.003071</td>\n",
              "      <td>-0.000840</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000679</td>\n",
              "      <td>-0.000076</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.000296</td>\n",
              "      <td>-0.000462</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.003847</td>\n",
              "      <td>-0.000157</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.001716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.000211</td>\n",
              "      <td>0.000602</td>\n",
              "      <td>0.000401</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>-0.000028</td>\n",
              "      <td>-0.000181</td>\n",
              "      <td>0.000731</td>\n",
              "      <td>0.000742</td>\n",
              "      <td>0.000297</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000326</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.000491</td>\n",
              "      <td>0.000495</td>\n",
              "      <td>0.000673</td>\n",
              "      <td>-0.001379</td>\n",
              "      <td>0.003167</td>\n",
              "      <td>-0.000271</td>\n",
              "      <td>0.000603</td>\n",
              "      <td>-0.000206</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 256 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b2137b3-3b7e-4123-bd16-2bd4aed8cf53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6b2137b3-3b7e-4123-bd16-2bd4aed8cf53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6b2137b3-3b7e-4123-bd16-2bd4aed8cf53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-56ea29d6-e8af-4570-bfbc-0a7c937f5263\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56ea29d6-e8af-4570-bfbc-0a7c937f5263')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-56ea29d6-e8af-4570-bfbc-0a7c937f5263 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label=pd.DataFrame(label)"
      ],
      "metadata": {
        "id": "HIWWKzhW9IPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rang"
      ],
      "metadata": {
        "id": "zhYDzOHi88CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label.columns = ['y']"
      ],
      "metadata": {
        "id": "_Gw80iNX83dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[X,label]"
      ],
      "metadata": {
        "id": "xM1zny3583Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data=pd.concat(data,axis=1)"
      ],
      "metadata": {
        "id": "VZzLCVX_9SKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "Ymh01evG9SF6",
        "outputId": "e249f5db-e8ba-499b-ec9f-117ce92fcc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.000075 -0.000472  0.000911 -0.000558 -0.000210  0.000728  0.000435   \n",
              "1 -0.000094 -0.000918  0.000047 -0.000788  0.000836  0.003866 -0.000262   \n",
              "2 -0.000301 -0.004723 -0.000028 -0.000488 -0.000082  0.000015 -0.000032   \n",
              "3 -0.000467 -0.000024  0.000575 -0.000436 -0.000581  0.001565  0.000517   \n",
              "4 -0.000211  0.000602  0.000401  0.000050  0.000215 -0.000028 -0.000181   \n",
              "\n",
              "          7         8         9  ...       247       248       249       250  \\\n",
              "0  0.000249 -0.003544 -0.000089  ... -0.000120  0.000022 -0.000243  0.000022   \n",
              "1  0.000394  0.000972  0.001301  ...  0.000675  0.000642  0.002054  0.000390   \n",
              "2 -0.000196 -0.001213 -0.000569  ...  0.000387  0.000474 -0.001055  0.000648   \n",
              "3  0.000475 -0.003071 -0.000840  ... -0.000076  0.000345  0.000296 -0.000462   \n",
              "4  0.000731  0.000742  0.000297  ...  0.000312  0.000491  0.000495  0.000673   \n",
              "\n",
              "        251       252       253       254       255  y  \n",
              "0  0.000352  0.003680  0.000468 -0.000218  0.002066  4  \n",
              "1 -0.000314  0.004354  0.000843 -0.001050  0.001511  4  \n",
              "2 -0.001065  0.003007  0.000007 -0.000189  0.001184  4  \n",
              "3  0.000490  0.003847 -0.000157  0.000026  0.001716  4  \n",
              "4 -0.001379  0.003167 -0.000271  0.000603 -0.000206  4  \n",
              "\n",
              "[5 rows x 257 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-179c5222-5724-46bb-81ff-f18f7d7367c7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000075</td>\n",
              "      <td>-0.000472</td>\n",
              "      <td>0.000911</td>\n",
              "      <td>-0.000558</td>\n",
              "      <td>-0.000210</td>\n",
              "      <td>0.000728</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>-0.003544</td>\n",
              "      <td>-0.000089</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000120</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>-0.000243</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000352</td>\n",
              "      <td>0.003680</td>\n",
              "      <td>0.000468</td>\n",
              "      <td>-0.000218</td>\n",
              "      <td>0.002066</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.000094</td>\n",
              "      <td>-0.000918</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>-0.000788</td>\n",
              "      <td>0.000836</td>\n",
              "      <td>0.003866</td>\n",
              "      <td>-0.000262</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>0.000972</td>\n",
              "      <td>0.001301</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000675</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.002054</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>-0.000314</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>0.000843</td>\n",
              "      <td>-0.001050</td>\n",
              "      <td>0.001511</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.000301</td>\n",
              "      <td>-0.004723</td>\n",
              "      <td>-0.000028</td>\n",
              "      <td>-0.000488</td>\n",
              "      <td>-0.000082</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>-0.000032</td>\n",
              "      <td>-0.000196</td>\n",
              "      <td>-0.001213</td>\n",
              "      <td>-0.000569</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>-0.001055</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>-0.001065</td>\n",
              "      <td>0.003007</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-0.000189</td>\n",
              "      <td>0.001184</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.000467</td>\n",
              "      <td>-0.000024</td>\n",
              "      <td>0.000575</td>\n",
              "      <td>-0.000436</td>\n",
              "      <td>-0.000581</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.000517</td>\n",
              "      <td>0.000475</td>\n",
              "      <td>-0.003071</td>\n",
              "      <td>-0.000840</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000076</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.000296</td>\n",
              "      <td>-0.000462</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.003847</td>\n",
              "      <td>-0.000157</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.001716</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.000211</td>\n",
              "      <td>0.000602</td>\n",
              "      <td>0.000401</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>-0.000028</td>\n",
              "      <td>-0.000181</td>\n",
              "      <td>0.000731</td>\n",
              "      <td>0.000742</td>\n",
              "      <td>0.000297</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.000491</td>\n",
              "      <td>0.000495</td>\n",
              "      <td>0.000673</td>\n",
              "      <td>-0.001379</td>\n",
              "      <td>0.003167</td>\n",
              "      <td>-0.000271</td>\n",
              "      <td>0.000603</td>\n",
              "      <td>-0.000206</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 257 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-179c5222-5724-46bb-81ff-f18f7d7367c7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-179c5222-5724-46bb-81ff-f18f7d7367c7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-179c5222-5724-46bb-81ff-f18f7d7367c7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-10ad9053-f487-4a4f-b134-313a2d2dda0c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10ad9053-f487-4a4f-b134-313a2d2dda0c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-10ad9053-f487-4a4f-b134-313a2d2dda0c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_data[\"y\"]=X_data[\"y\"].astype('category')\n",
        "X_data[\"y\"]=X_data[\"y\"].cat.codes"
      ],
      "metadata": {
        "id": "XNZpVz9O9SBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5- Data preparation"
      ],
      "metadata": {
        "id": "Rf5_vbdKVHLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from  sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import  Dense, BatchNormalization, Activation, Add"
      ],
      "metadata": {
        "id": "6naUcpcwVHBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=X_data.loc[:, X_data.columns != 'y']"
      ],
      "metadata": {
        "id": "C0OBLtpIVG9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=X"
      ],
      "metadata": {
        "id": "_oBF6omLRDeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC5E5FS1NKlJ",
        "outputId": "4f39cd85-c348-4733-ddef-235909f4b50b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 478
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=X_data['y']"
      ],
      "metadata": {
        "id": "vLGQRTlhVG7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=[1] * 54"
      ],
      "metadata": {
        "id": "zeNBIcNzGiQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.array(x_train)\n",
        "y_train=np.array(y_train)"
      ],
      "metadata": {
        "id": "61ECgH-KVG4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x_concept=scaler.fit_transform(x_concept)"
      ],
      "metadata": {
        "id": "ZBLTNO20VG1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLG3dqDUVZXP",
        "outputId": "463c3cd1-0a85-4ba7-9828-4b74f79cdc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54,)"
            ]
          },
          "metadata": {},
          "execution_count": 482
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################################\"\""
      ],
      "metadata": {
        "id": "STiZk4pYOcla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_bis=X_bis"
      ],
      "metadata": {
        "id": "HZOL-oNzOciN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_bis=[0] * 27"
      ],
      "metadata": {
        "id": "lgiHlsdPOcew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_bis=np.array(x_train_bis)"
      ],
      "metadata": {
        "id": "SvGDtTkxOcZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_bis.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzNiK5iEOiJ7",
        "outputId": "b9665018-8c93-4b15-bc97-43ca8ac075a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 497
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_bis=np.array(x_train_bis)\n",
        "y_train_bis=np.array(y_train_bis)"
      ],
      "metadata": {
        "id": "XAzN24RnOiG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_concept=np.concatenate((x_train, x_train_bis))"
      ],
      "metadata": {
        "id": "10B1Gm-OOiCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_concept.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_cjwTS9PQIx",
        "outputId": "bef5be7c-3624-4343-901a-29cbde1bb18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 503
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_concept=np.concatenate((y_train, y_train_bis))"
      ],
      "metadata": {
        "id": "jrH3R0HLPQEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_concept.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FTNxxzcQIOg",
        "outputId": "3578293c-5995-45c3-e106-b1d8e3a914ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81,)"
            ]
          },
          "metadata": {},
          "execution_count": 505
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dO98W7bLOh_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6- Autoencoder classifier"
      ],
      "metadata": {
        "id": "kw-ZMhHEU7ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, MaxPool2D, GlobalAveragePooling2D, Add\n",
        "from tensorflow.keras import Model\n",
        "import tensorflow.keras as keras\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "31ZaLe7kVkxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_dim=2\n",
        "input=x_concept.shape[1]\n",
        "# Deep NN\n",
        "input_img = keras.Input(shape=(input,))\n",
        "encoded = layers.Dense(200, activation='relu')(input_img)\n",
        "encoded = layers.Dense(150, activation='relu')(encoded)\n",
        "encoded = layers.Dense(100, activation='relu')(encoded)\n",
        "encoded = layers.Dense(50, activation='relu')(encoded)\n",
        "encoded = layers.Dense(20, activation='relu')(encoded)\n",
        "encoded = layers.Dense(10, activation='relu')(encoded)\n",
        "encoded = layers.Dense(encoding_dim, activation='linear')(encoded)\n",
        "\n",
        "decoded = layers.Dense(10, activation='relu')(encoded)\n",
        "decoded = layers.Dense(20, activation='relu')(decoded)\n",
        "decoded = layers.Dense(50, activation='relu')(decoded)\n",
        "decoded = layers.Dense(100, activation='relu')(decoded)\n",
        "decoded = layers.Dense(150, activation='relu')(decoded)\n",
        "decoded = layers.Dense(200, activation='relu')(decoded)\n",
        "decoded = layers.Dense(x_train.shape[1], activation='sigmoid')(decoded)"
      ],
      "metadata": {
        "id": "TNQY_0Re9R9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = keras.Model(input_img, decoded)"
      ],
      "metadata": {
        "id": "-zFdzLJGU7MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSAJ5mQvU7Iy",
        "outputId": "32e0b585-31c6-4d07-a029-15715f9c2dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 512)]             0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 200)               102600    \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 150)               30150     \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 100)               15100     \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 20)                1020      \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 2)                 22        \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 10)                30        \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 20)                220       \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 50)                1050      \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 100)               5100      \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 150)               15150     \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 200)               30200     \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 512)               102912    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 308814 (1.18 MB)\n",
            "Trainable params: 308814 (1.18 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "Rj04zy9FV01W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_concept, x_concept,\n",
        "                epochs=500,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_concept, x_concept)\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQNWd4FnU7GQ",
        "outputId": "2e25e87e-581d-423a-9235-70d7a9460604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6931 - val_loss: 0.6929\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6929 - val_loss: 0.6925\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6925 - val_loss: 0.6920\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6920 - val_loss: 0.6910\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6910 - val_loss: 0.6894\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6894 - val_loss: 0.6866\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6866 - val_loss: 0.6820\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6820 - val_loss: 0.6749\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6749 - val_loss: 0.6647\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6647 - val_loss: 0.6515\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6515 - val_loss: 0.6377\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6377 - val_loss: 0.6303\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6303 - val_loss: 0.6297\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6297 - val_loss: 0.6211\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6211 - val_loss: 0.6095\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6095 - val_loss: 0.6019\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6019 - val_loss: 0.5984\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5984 - val_loss: 0.5961\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5961 - val_loss: 0.5931\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5931 - val_loss: 0.5896\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5896 - val_loss: 0.5871\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5871 - val_loss: 0.5866\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5866 - val_loss: 0.5868\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5868 - val_loss: 0.5858\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5858 - val_loss: 0.5840\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5840 - val_loss: 0.5829\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5829 - val_loss: 0.5829\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5829 - val_loss: 0.5831\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5831 - val_loss: 0.5827\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5827 - val_loss: 0.5820\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5820 - val_loss: 0.5813\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5813 - val_loss: 0.5812\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5812 - val_loss: 0.5812\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5812 - val_loss: 0.5809\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5809 - val_loss: 0.5802\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5802 - val_loss: 0.5797\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5797 - val_loss: 0.5796\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5796 - val_loss: 0.5796\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5796 - val_loss: 0.5793\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5793 - val_loss: 0.5789\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5789 - val_loss: 0.5787\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.5787 - val_loss: 0.5787\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5787 - val_loss: 0.5786\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5786 - val_loss: 0.5784\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5784 - val_loss: 0.5782\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5782 - val_loss: 0.5782\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5782 - val_loss: 0.5781\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5781 - val_loss: 0.5780\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5780 - val_loss: 0.5778\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5778 - val_loss: 0.5777\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5777 - val_loss: 0.5777\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5777 - val_loss: 0.5776\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5776 - val_loss: 0.5774\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5774 - val_loss: 0.5774\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5774 - val_loss: 0.5774\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5774 - val_loss: 0.5773\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5773 - val_loss: 0.5772\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5772 - val_loss: 0.5772\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5772 - val_loss: 0.5772\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5772 - val_loss: 0.5771\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5771 - val_loss: 0.5771\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5771 - val_loss: 0.5771\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5771 - val_loss: 0.5771\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5771 - val_loss: 0.5771\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5771 - val_loss: 0.5770\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5770 - val_loss: 0.5770\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5770 - val_loss: 0.5770\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5770 - val_loss: 0.5770\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5770 - val_loss: 0.5769\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5769 - val_loss: 0.5769\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5769 - val_loss: 0.5769\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5769 - val_loss: 0.5769\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5769 - val_loss: 0.5769\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5769 - val_loss: 0.5769\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5769 - val_loss: 0.5769\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5769 - val_loss: 0.5769\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5769 - val_loss: 0.5769\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5769 - val_loss: 0.5768\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5768 - val_loss: 0.5768\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5768 - val_loss: 0.5768\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5768 - val_loss: 0.5768\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5768 - val_loss: 0.5768\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5768 - val_loss: 0.5768\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5768 - val_loss: 0.5768\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5768 - val_loss: 0.5768\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5768 - val_loss: 0.5768\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5768 - val_loss: 0.5768\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5768 - val_loss: 0.5768\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5768 - val_loss: 0.5767\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5767 - val_loss: 0.5767\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5767 - val_loss: 0.5766\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5766 - val_loss: 0.5766\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5766 - val_loss: 0.5766\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5766 - val_loss: 0.5766\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5766 - val_loss: 0.5766\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5766 - val_loss: 0.5766\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5766 - val_loss: 0.5766\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5766 - val_loss: 0.5766\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5766 - val_loss: 0.5766\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5766 - val_loss: 0.5766\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5766 - val_loss: 0.5766\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5766 - val_loss: 0.5766\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5766 - val_loss: 0.5765\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5765 - val_loss: 0.5765\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5765 - val_loss: 0.5765\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5765 - val_loss: 0.5765\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5765 - val_loss: 0.5765\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5765 - val_loss: 0.5765\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5765 - val_loss: 0.5765\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5765 - val_loss: 0.5765\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5765 - val_loss: 0.5765\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5765 - val_loss: 0.5764\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.5764 - val_loss: 0.5764\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5764 - val_loss: 0.5764\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5764 - val_loss: 0.5764\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5764 - val_loss: 0.5764\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5764 - val_loss: 0.5764\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5764 - val_loss: 0.5764\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5764 - val_loss: 0.5763\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5763 - val_loss: 0.5763\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5763 - val_loss: 0.5763\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5763 - val_loss: 0.5763\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5763 - val_loss: 0.5763\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5763 - val_loss: 0.5762\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5762 - val_loss: 0.5762\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5762 - val_loss: 0.5762\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5762 - val_loss: 0.5762\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5762 - val_loss: 0.5762\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5762 - val_loss: 0.5761\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5761 - val_loss: 0.5761\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5761 - val_loss: 0.5761\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5761 - val_loss: 0.5760\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5760 - val_loss: 0.5760\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5760 - val_loss: 0.5760\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5760 - val_loss: 0.5759\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.5759 - val_loss: 0.5759\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5759 - val_loss: 0.5759\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5759 - val_loss: 0.5758\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5758 - val_loss: 0.5758\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5758 - val_loss: 0.5757\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5757 - val_loss: 0.5757\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5757 - val_loss: 0.5756\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5756 - val_loss: 0.5756\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5756 - val_loss: 0.5755\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5755 - val_loss: 0.5754\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5754 - val_loss: 0.5754\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5754 - val_loss: 0.5753\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5753 - val_loss: 0.5752\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5752 - val_loss: 0.5751\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5751 - val_loss: 0.5750\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5750 - val_loss: 0.5750\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5750 - val_loss: 0.5749\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5749 - val_loss: 0.5748\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5748 - val_loss: 0.5746\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5746 - val_loss: 0.5745\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.5745 - val_loss: 0.5743\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5743 - val_loss: 0.5742\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5742 - val_loss: 0.5741\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5741 - val_loss: 0.5740\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5740 - val_loss: 0.5737\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5737 - val_loss: 0.5736\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5736 - val_loss: 0.5736\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5736 - val_loss: 0.5732\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5732 - val_loss: 0.5731\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5731 - val_loss: 0.5731\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5731 - val_loss: 0.5728\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5728 - val_loss: 0.5727\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5727 - val_loss: 0.5723\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5723 - val_loss: 0.5722\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5722 - val_loss: 0.5719\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5719 - val_loss: 0.5719\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5719 - val_loss: 0.5718\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5718 - val_loss: 0.5717\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5717 - val_loss: 0.5713\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5713 - val_loss: 0.5714\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5714 - val_loss: 0.5710\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5710 - val_loss: 0.5711\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5711 - val_loss: 0.5709\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5709 - val_loss: 0.5707\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5707 - val_loss: 0.5707\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5707 - val_loss: 0.5705\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.5705 - val_loss: 0.5704\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5704 - val_loss: 0.5703\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5703 - val_loss: 0.5702\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5702 - val_loss: 0.5701\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5701 - val_loss: 0.5700\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5700 - val_loss: 0.5699\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5699 - val_loss: 0.5699\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5699 - val_loss: 0.5698\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5698 - val_loss: 0.5697\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5697 - val_loss: 0.5697\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5697 - val_loss: 0.5696\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5696 - val_loss: 0.5695\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5695 - val_loss: 0.5697\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5697 - val_loss: 0.5698\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5698 - val_loss: 0.5707\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5707 - val_loss: 0.5695\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5695 - val_loss: 0.5703\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5703 - val_loss: 0.5694\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5694 - val_loss: 0.5698\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5698 - val_loss: 0.5693\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5693 - val_loss: 0.5696\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5696 - val_loss: 0.5689\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5689 - val_loss: 0.5693\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5693 - val_loss: 0.5687\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5687 - val_loss: 0.5689\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5689 - val_loss: 0.5684\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5684 - val_loss: 0.5686\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5686 - val_loss: 0.5682\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5682 - val_loss: 0.5682\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5682 - val_loss: 0.5680\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5680 - val_loss: 0.5678\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5678 - val_loss: 0.5679\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5679 - val_loss: 0.5677\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5677 - val_loss: 0.5672\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5672 - val_loss: 0.5678\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5678 - val_loss: 0.5681\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5681 - val_loss: 0.5668\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5668 - val_loss: 0.5684\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5684 - val_loss: 0.5683\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5683 - val_loss: 0.5674\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5674 - val_loss: 0.5677\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5677 - val_loss: 0.5663\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5663 - val_loss: 0.5667\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5667 - val_loss: 0.5660\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5660 - val_loss: 0.5663\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5663 - val_loss: 0.5655\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5655 - val_loss: 0.5658\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5658 - val_loss: 0.5651\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5651 - val_loss: 0.5654\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5654 - val_loss: 0.5647\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5647 - val_loss: 0.5649\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5649 - val_loss: 0.5644\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5644 - val_loss: 0.5640\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5640 - val_loss: 0.5640\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5640 - val_loss: 0.5635\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5635 - val_loss: 0.5637\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5637 - val_loss: 0.5647\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5647 - val_loss: 0.5632\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5632 - val_loss: 0.5647\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5647 - val_loss: 0.5634\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5634 - val_loss: 0.5633\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5633 - val_loss: 0.5642\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5642 - val_loss: 0.5639\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5639 - val_loss: 0.5637\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5637 - val_loss: 0.5642\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5642 - val_loss: 0.5626\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5626 - val_loss: 0.5634\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5634 - val_loss: 0.5623\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5623 - val_loss: 0.5627\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5627 - val_loss: 0.5629\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5629 - val_loss: 0.5620\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5620 - val_loss: 0.5636\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5636 - val_loss: 0.5642\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5642 - val_loss: 0.5648\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5648 - val_loss: 0.5626\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5626 - val_loss: 0.5650\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5650 - val_loss: 0.5623\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5623 - val_loss: 0.5627\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5627 - val_loss: 0.5633\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5633 - val_loss: 0.5616\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5616 - val_loss: 0.5632\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5632 - val_loss: 0.5610\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5610 - val_loss: 0.5615\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5615 - val_loss: 0.5612\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5612 - val_loss: 0.5613\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5613 - val_loss: 0.5609\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5609 - val_loss: 0.5610\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5610 - val_loss: 0.5608\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5608 - val_loss: 0.5609\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5609 - val_loss: 0.5605\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5605 - val_loss: 0.5608\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5608 - val_loss: 0.5604\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5604 - val_loss: 0.5608\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5608 - val_loss: 0.5606\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5606 - val_loss: 0.5605\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5605 - val_loss: 0.5604\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5604 - val_loss: 0.5604\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5604 - val_loss: 0.5604\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5604 - val_loss: 0.5604\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5604 - val_loss: 0.5602\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5602 - val_loss: 0.5602\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5602 - val_loss: 0.5602\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5602 - val_loss: 0.5602\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5602 - val_loss: 0.5601\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5601 - val_loss: 0.5601\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5601 - val_loss: 0.5600\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5600 - val_loss: 0.5601\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5601 - val_loss: 0.5600\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5600 - val_loss: 0.5600\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5600 - val_loss: 0.5600\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5600 - val_loss: 0.5600\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5600 - val_loss: 0.5599\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5599 - val_loss: 0.5599\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5599 - val_loss: 0.5599\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5599 - val_loss: 0.5599\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5599 - val_loss: 0.5599\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5599 - val_loss: 0.5598\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5598 - val_loss: 0.5599\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5599 - val_loss: 0.5598\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5598 - val_loss: 0.5598\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5598 - val_loss: 0.5598\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5598 - val_loss: 0.5598\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5598 - val_loss: 0.5598\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5598 - val_loss: 0.5598\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5598 - val_loss: 0.5598\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5598 - val_loss: 0.5597\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5597 - val_loss: 0.5598\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5598 - val_loss: 0.5597\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5597 - val_loss: 0.5597\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5597 - val_loss: 0.5597\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5597 - val_loss: 0.5597\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5597 - val_loss: 0.5597\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5597 - val_loss: 0.5597\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5597 - val_loss: 0.5597\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5597 - val_loss: 0.5597\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5597 - val_loss: 0.5597\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5597 - val_loss: 0.5597\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5597 - val_loss: 0.5597\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5597 - val_loss: 0.5596\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5596 - val_loss: 0.5596\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5596 - val_loss: 0.5595\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5595 - val_loss: 0.5595\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5595 - val_loss: 0.5594\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5594 - val_loss: 0.5594\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5594 - val_loss: 0.5594\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5594 - val_loss: 0.5594\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5594 - val_loss: 0.5594\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5594 - val_loss: 0.5594\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5594 - val_loss: 0.5594\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5594 - val_loss: 0.5594\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5594 - val_loss: 0.5594\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5594 - val_loss: 0.5593\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5593 - val_loss: 0.5594\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5594 - val_loss: 0.5594\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5594 - val_loss: 0.5593\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5593 - val_loss: 0.5594\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5594 - val_loss: 0.5593\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5593 - val_loss: 0.5593\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5593 - val_loss: 0.5593\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5593 - val_loss: 0.5594\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5594 - val_loss: 0.5593\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5593 - val_loss: 0.5593\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5593 - val_loss: 0.5593\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5593 - val_loss: 0.5592\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5592 - val_loss: 0.5593\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5593 - val_loss: 0.5593\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5593 - val_loss: 0.5592\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5592 - val_loss: 0.5593\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5593 - val_loss: 0.5593\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5593 - val_loss: 0.5592\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5592 - val_loss: 0.5592\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5592 - val_loss: 0.5592\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5592 - val_loss: 0.5591\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5591 - val_loss: 0.5592\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5592 - val_loss: 0.5591\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5591 - val_loss: 0.5591\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5591 - val_loss: 0.5591\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5591 - val_loss: 0.5591\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5591 - val_loss: 0.5590\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5590 - val_loss: 0.5591\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5591 - val_loss: 0.5591\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5591 - val_loss: 0.5590\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5590 - val_loss: 0.5591\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5591 - val_loss: 0.5591\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5591 - val_loss: 0.5590\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5590 - val_loss: 0.5590\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5590 - val_loss: 0.5590\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5590 - val_loss: 0.5589\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5589 - val_loss: 0.5590\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5590 - val_loss: 0.5591\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5591 - val_loss: 0.5589\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5589 - val_loss: 0.5589\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5589 - val_loss: 0.5590\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5590 - val_loss: 0.5588\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5588 - val_loss: 0.5589\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5589 - val_loss: 0.5590\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5590 - val_loss: 0.5588\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5588 - val_loss: 0.5588\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5588 - val_loss: 0.5589\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5589 - val_loss: 0.5587\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5587 - val_loss: 0.5588\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.5588 - val_loss: 0.5589\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5589 - val_loss: 0.5587\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5587 - val_loss: 0.5587\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5587 - val_loss: 0.5589\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5589 - val_loss: 0.5586\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5586 - val_loss: 0.5587\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5587 - val_loss: 0.5589\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5589 - val_loss: 0.5586\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5586 - val_loss: 0.5586\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5586 - val_loss: 0.5588\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5588 - val_loss: 0.5585\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5585 - val_loss: 0.5586\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5586 - val_loss: 0.5589\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5589 - val_loss: 0.5585\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5585 - val_loss: 0.5585\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5585 - val_loss: 0.5590\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5590 - val_loss: 0.5584\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5584 - val_loss: 0.5587\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5587 - val_loss: 0.5589\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5589 - val_loss: 0.5582\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5582 - val_loss: 0.5590\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5590 - val_loss: 0.5595\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5595 - val_loss: 0.5582\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5582 - val_loss: 0.5595\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5595 - val_loss: 0.5589\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5589 - val_loss: 0.5587\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5587 - val_loss: 0.5593\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5593 - val_loss: 0.5580\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5580 - val_loss: 0.5588\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5588 - val_loss: 0.5577\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5577 - val_loss: 0.5586\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5586 - val_loss: 0.5579\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5579 - val_loss: 0.5579\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5579 - val_loss: 0.5578\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5578 - val_loss: 0.5573\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5573 - val_loss: 0.5575\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5575 - val_loss: 0.5572\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5572 - val_loss: 0.5571\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5571 - val_loss: 0.5571\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5571 - val_loss: 0.5569\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5569 - val_loss: 0.5571\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5571 - val_loss: 0.5576\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5576 - val_loss: 0.5565\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5565 - val_loss: 0.5577\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5577 - val_loss: 0.5590\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5590 - val_loss: 0.5566\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5566 - val_loss: 0.5597\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5597 - val_loss: 0.5578\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5578 - val_loss: 0.5583\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5583 - val_loss: 0.5576\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5576 - val_loss: 0.5573\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5573 - val_loss: 0.5575\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5575 - val_loss: 0.5574\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5574 - val_loss: 0.5569\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5569 - val_loss: 0.5569\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.5569 - val_loss: 0.5567\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5567 - val_loss: 0.5566\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5566 - val_loss: 0.5563\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5563 - val_loss: 0.5560\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5560 - val_loss: 0.5563\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5563 - val_loss: 0.5556\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5556 - val_loss: 0.5565\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5565 - val_loss: 0.5556\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5556 - val_loss: 0.5558\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5558 - val_loss: 0.5555\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5555 - val_loss: 0.5551\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5551 - val_loss: 0.5552\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5552 - val_loss: 0.5550\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5550 - val_loss: 0.5549\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5549 - val_loss: 0.5550\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5550 - val_loss: 0.5547\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5547 - val_loss: 0.5548\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5548 - val_loss: 0.5547\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5547 - val_loss: 0.5544\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5544 - val_loss: 0.5546\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5546 - val_loss: 0.5548\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5548 - val_loss: 0.5542\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5542 - val_loss: 0.5548\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5548 - val_loss: 0.5553\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5553 - val_loss: 0.5544\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5544 - val_loss: 0.5554\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5554 - val_loss: 0.5543\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c6dd17d56c0>"
            ]
          },
          "metadata": {},
          "execution_count": 512
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode and decode some digits\n",
        "# Note that we take them from the *test* set\n",
        "# This model maps an input to its encoded representation\n",
        "encoder = keras.Model(input_img, encoded)\n",
        "encoded_imgs = encoder.predict(x_concept)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHSQcUgvV6r1",
        "outputId": "d2409b64-1d2b-4190-f6f5-7e63d5af3d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c6d9f69dd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(encoded_imgs[:, 0], encoded_imgs[:, 1], c=y_concept)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "Lp35DPseU7E1",
        "outputId": "8e56d7fd-ecac-4703-8781-99121ca1ef99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_imgs"
      ],
      "metadata": {
        "id": "Vk5gR8WjU7Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.where((encoded_imgs[:,0]>-23) & (encoded_imgs[:,0]<-15) & (encoded_imgs[:,1]<5) & (encoded_imgs[:,1]>0) )"
      ],
      "metadata": {
        "id": "ZZLW5y0GYwHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f915df-5ef8-4ec7-b3c3-15d533307c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 5, 18, 19, 28, 40, 44, 46, 51]),)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(np.unique(label))"
      ],
      "metadata": {
        "id": "jRZ6Pq7_pFIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2679e44-e485-4fde-f469-751f71b3a44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        " transforms.Resize(256),\n",
        " transforms.CenterCrop(224),\n",
        " transforms.ToTensor()\n",
        "])\n",
        "\n",
        "transform_normalize = transforms.Normalize(\n",
        "     mean=[0.485, 0.456, 0.406],\n",
        "     std=[0.229, 0.224, 0.225]\n",
        " )\n",
        "\n",
        "img = Image.open('/content/animal_103.jpg')\n",
        "\n",
        "transformed_img = transform(img)\n",
        "\n",
        "input = transform_normalize(transformed_img)\n",
        "input = input.unsqueeze(0)\n",
        "\n",
        "output = model(input)\n",
        "output = F.softmax(output, dim=1)\n",
        "prediction_score, pred_label_idx = torch.topk(output, 1)\n",
        "\n",
        "pred_label_idx.squeeze_()\n",
        "predicted_label = idx_to_labels[str(pred_label_idx.item())][1]\n",
        "print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbH2x89ak3st",
        "outputId": "ce87bc04-ea64-40e9-87b3-2d5e3b525a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: chimpanzee ( 0.9983150959014893 )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FF92x8lak3up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fM4R3_cjk3zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mxd0Nuobk31r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9s7gJh4zYg_W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}